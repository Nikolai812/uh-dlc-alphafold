#!/bin/bash
#SBATCH -p dlc
#SBATCH --gres=gpu:1
#SBATCH -N 1
#SBATCH -c 16
#SBATCH -t 48:00:00
#SBATCH --error=%J.splitmono.out
#SBATCH --output=%J.splitmono.out

FASTA=dm_dataset_new_20250322.fasta
#FASTA=dm1.fasta

echo "======================================================="
echo "This script can handle multiple monomer sequences in one file"
echo ""
echo "======================================================="
echo ""
echo "Starting JOB ${SLURM_JOBID} formultiple mono input ${FASTA}  at $(date)"
echo "======================================================="

BASEDIR=/users/dchelouche/nromanenk/rachel
KOSLOFFDIR=/users/kosloff
OUTPUTS=${BASEDIR}/woutputs/${SLURM_JOBID}
echo ""
echo "Creating the output directory SUBMONO for the alphafold2 outputs"
echo ""

srun bash -c "mkdir $OUTPUTS"

mounts="${BASEDIR}:/mount,${KOSLOFFDIR}/alphafold_data:/data,${OUTPUTS}:/outputs,${BASEDIR}/AF_inputs/:/AF_inputs"


echo ""
echo "Creating the output directory SUBMONO for the split files"
echo ""
srun bash -c "mkdir -p ${BASEDIR}/AF_inputs/SUBMONO"

echo "== Call the Python script and capture the output file names "
SPLITTED_FILES=$(srun python3 fasta_splitter.py "-i=${BASEDIR}/AF_inputs/${FASTA}" "-o=${BASEDIR}/AF_inputs/SUBMONO")

# Output the list of split files
echo "== Split files: $SPLITTED_FILES"

# Optionally, you can loop through the split files and perform additional operations
for file in $SPLITTED_FILES; do
    echo "Start processing file: $file  at $(date)"
    
    RUNOPTS="--model_preset=monomer \
        --fasta_paths=/AF_inputs/SUBMONO/${file} \
        --output_dir=/outputs --data_dir=/data/ \
        --mgnify_database_path=/data/mgnify/mgy_clusters_2018_12.fa \
        --template_mmcif_dir=/data/pdb_mmcif/mmcif_files/ \
        --max_template_date=2020-05-14 \
        --obsolete_pdbs_path=/data/pdb_mmcif/obsolete.dat \
        --use_gpu_relax=False \
        --bfd_database_path=/data/bfd/bfd_metaclust_clu_complete_id30_c90_final_seq.sorted_opt \
        --uniref90_database_path=/data/uniref90/uniref90.fasta \
        --uniclust30_database_path=/data/uniclust30/uniclust30_2018_08/uniclust30_2018_08 \
        --pdb70_database_path=/data/pdb70/pdb70"

    srun -l \
        --container-image=${BASEDIR}/AF_image.sqsh \
        --container-mounts=${mounts} \
        --container-workdir=/app/alphafold \
        --no-container-entrypoint \
        python /app/alphafold/run_alphafold.py $RUNOPTS

    echo "==="
    echo "End processing file: $file  at $(date)"
    echo "==="

done


echo "======================================================="
echo "JOB ${SLURM_JOBID} completed at $(date)"
echo "======================================================="

